# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lZaSsMCAaO8L9-Zj02N8V0ySH0lyth4G
"""

import locale
locale.getpreferredencoding = lambda: "UTF-8"

!pip install transformers
!pip install accelerate
!pip install optimum
!pip install auto-gptq

!pip install sentence-transformers
!pip install umap-learn
!pip install hdbscan

!pip install bertopic

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_name_or_path = "TheBloke/Llama-2-7b-Chat-GPTQ"
# To use a different branch, change revision
# For example: revision="gptq-4bit-64g-actorder_True"
model = AutoModelForCausalLM.from_pretrained(model_name_or_path,
                                             torch_dtype=torch.float16,
                                             device_map="auto",
                                             revision="main")

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)

model.eval()

# Our text generator
import transformers
generator = transformers.pipeline(
    model=model, tokenizer=tokenizer,
    task='text-generation',
    temperature=0.1,
    max_new_tokens=500,
    repetition_penalty=1.1
)

# System prompt describes information given to all conversations
system_prompt = """
<s>[INST] <<SYS>>
You are a helpful, respectful and honest assistant for labeling topics.
<</SYS>>
"""

# Example prompt demonstrating the output we are looking for
example_prompt = """
I have a topic that contains the following documents:
- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.
- Meat, but especially beef, is the word food in terms of emissions.
- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.

The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.

Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.
[/INST] Environmental impacts of eating meat
"""

# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags
main_prompt = """
[INST]
I have a topic that contains the following documents:
[DOCUMENTS]

The topic is described by the following keywords: '[KEYWORDS]'.

Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.
[/INST]
"""

prompt = system_prompt + example_prompt + main_prompt

print(prompt)

import json
import pandas as pd
from datetime import datetime

def read_json(path):
    with open(path, encoding='utf-8') as f:
        data = json.load(f)
    return data

data = read_json("MyActivity.json")

def get_titles(data):
    titles = []
    for d in data:
        if d['title'][:12] == "Searched for":
                try:
                    titles.append([d['title'][len("Searched for"):].strip(), datetime.strptime(d['time'], '%Y-%m-%dT%H:%M:%S.%fZ')])
                except:
                    titles.append([d['title'][len("Searched for"):].strip(), datetime.strptime(d['time'], '%Y-%m-%dT%H:%M:%SZ')])
    return titles

titles = get_titles(data)

titles_df = pd.DataFrame(titles)
titles_df.columns = ['title','datetime']

from sentence_transformers import SentenceTransformer

# Pre-calculate embeddings
embedding_model = SentenceTransformer("BAAI/bge-small-en")
embeddings = embedding_model.encode(titles_df['title'], show_progress_bar=True)

from umap import UMAP
from hdbscan import HDBSCAN

umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)
hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)

# Pre-reduce embeddings for visualization purposes
reduced_embeddings = umap_model.fit_transform(embeddings)

from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, TextGeneration

# KeyBERT
keybert = KeyBERTInspired()

# MMR
mmr = MaximalMarginalRelevance(diversity=0.3)

# Text generation with Llama 2
llama2 = TextGeneration(generator, prompt=prompt)

# All representation models
representation_model = {
    "KeyBERT": keybert,
    "Llama2": llama2,
    "MMR": mmr,
}

# Training
from bertopic import BERTopic

topic_model = BERTopic(

  # Sub-models
  embedding_model=embedding_model,
  umap_model=umap_model,
  hdbscan_model=hdbscan_model,
  representation_model=representation_model,

  # Hyperparameters
  top_n_words=10,
  verbose=True
)

# Train model
topics, probs = topic_model.fit_transform(titles_df['title'])

topic_model.get_topic_info()[1:4]

# Show top 3 least frequent topics
topic_model.get_topic_info()[-3:]



llama2_labels = [label[0][0].split("\n")[0] for label in topic_model.get_topics(full=True)["Llama2"].values()]
topic_model.set_topic_labels(llama2_labels)

topic_model.visualize_documents(titles,
                                reduced_embeddings=reduced_embeddings,
                                hide_annotations=True, hide_document_hover=False, custom_labels=True)

topics_over_time = topic_model.topics_over_time(titles_df['title'], titles_df['datetime'], nr_bins=20)

topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)

